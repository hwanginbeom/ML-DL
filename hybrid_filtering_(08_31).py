# -*- coding: utf-8 -*-
"""Hybrid Filtering_경현(08.31).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_gzEMZM7JyrF6aieGftTK7bhwf37e7cx
"""

# from google.colab import drive  # 구글 코랩에서 drive(내 구글 드라이브)를 사용하기 위한 함수
# import io
# drive.mount('/content/drive')  # 이렇게 하면 내 drive가 설정? 잡힌다.
#
# from google.colab import drive
# drive.mount('/content/drive')
#
# !pip install surprise

import pandas as pd # pandas 불러오기
import numpy as np # numpy 불러오기
import math # 불러오기 수학과 관련된 함수들
import re #정규표현식 함수 .맞는지 틀린지
from scipy.sparse import csr_matrix   # 매트릭스 해주는거.
import matplotlib.pyplot as plt # 시각화 함수
import seaborn as sns # 시각화 함수
from surprise import Reader, Dataset, SVD, NormalPredictor, KNNBasic
from surprise import KNNWithMeans, KNNWithZScore, KNNBaseline
from surprise import BaselineOnly, SVDpp,NMF, SlopeOne, CoClustering #분석툴
from surprise.accuracy import rmse
from surprise import accuracy
from surprise.model_selection import cross_validate, KFold, train_test_split
import json
import mpmath
from scipy.special import logsumexp

# from google.colab import drive
# drive.mount('/content/drive')

# ratings = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/ratings_small.csv',low_memory=False)
ratings = pd.read_csv('../data/ratings_small.csv',low_memory=False)
ratings = ratings[['userId', 'movieId', 'rating']]
ratings.head()
ratings.movieId = pd.to_numeric(ratings.movieId, errors='coerce')
ratings.userId = pd.to_numeric(ratings.userId, errors='coerce')
ratings.rating = pd.to_numeric(ratings.rating, errors='coerce')
len(ratings)
df = ratings
print(df)

p = df.groupby('rating')['rating'].agg(['count'])
movie_count = df['movieId'].nunique()
cust_count = df['userId'].nunique()
rating_count = df['userId'].count()
df = df[pd.notnull(df['rating'])]

f = ['count','mean']
df_movie_summary = df.groupby('movieId')['rating'].agg(f)
df_movie_summary.index = df_movie_summary.index.map(int) # map 함수 쓰면 한번에 형변환 처리 가능 , 스트나 튜플을 지정함수로 처리해주는 역할
movie_benchmark = round(df_movie_summary['count'].quantile(0.7),0)  #quantile 사분위수
drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index
print('Movie minimum times of review: {}'.format(movie_benchmark))

df_cust_summary = df.groupby('userId')['rating'].agg(f)
df_cust_summary.index = df_cust_summary.index.map(int)
cust_benchmark = round(df_cust_summary['count'].quantile(0.7),0)
drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index
print('Customer minimum times of review: {}'.format(cust_benchmark))

print('Original Shape: {}'.format(df.shape))
df = df[~df['movieId'].isin(drop_movie_list)] # df의 'Movie_Id'에서 drop_movie_list의 값이 있으면 True
print('df not isin dropmovie', df)
df = df[~df['userId'].isin(drop_cust_list)]
print('df not isin dropcust', df)
print('After Trim Shape: {}'.format(df.shape))
print('-Data Examples-')
print(df.iloc[::5000000, :])

df_p = pd.pivot_table(df,values='rating',index='userId',columns='movieId')
print(df_p)

meta = pd.read_csv('../content/drive/My Drive/data/the-movies-dataset/movies_metadata.csv',low_memory=False)

meta.head(10)

meta = meta[['id', 'original_title', 'genres']]
meta = meta.rename(columns={'id':'movieId'})
meta.movieId = pd.to_numeric(meta.movieId, errors='coerce')
meta.head()

reader = Reader()
data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)
kf = KFold(n_splits=3)
kf.split(data)
svd = SVD()
cross_validate(svd, data, measures=['RMSE', 'MAE']) #evaluate 대신 cross_validate사용

def userRec(data,usernumber,rating,moviedata,dropdata,reader,svd):
    df = data
    df_user = df[(df['userId'] == usernumber) & (df['rating'] == rating)]
    df_user = df_user.set_index('movieId')
    df_user = df_user.join(moviedata)['original_title']
    print(df_user)
    user_df = moviedata.copy()
    user_df = user_df[~user_df['movieId'].isin(dropdata)]
    data1 = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)
    trainset = data1.build_full_trainset()
    svd.fit(trainset)
    user_df['Estimate_Score'] = user_df['movieId'].apply(lambda x: svd.predict(usernumber, x).est)
    user_df = user_df.drop('movieId', axis = 1)
    user_df = user_df.sort_values('Estimate_Score', ascending=False)
    print(user_df.head(10))
userRec(df,665,5,meta,drop_movie_list,reader,svd)

#여기까지 user추천이었습니다.
#아래부터는 영화제목 추천입니다.

def parse_genres(genres_str):
    genres = json.loads(genres_str.replace('\'', '"'))
    
    genres_list = []
    for g in genres:
        genres_list.append(g['name'])

    return genres_list

meta['genres'] = meta['genres'].apply(parse_genres) #각 행에대해 함수를 적용하려면 apply를 써야 된다.

data = pd.merge(ratings, meta, on='movieId', how='inner')
data.head()

matrix = data.pivot_table(index='userId', columns='original_title', values='rating')
matrix.head(20)

GENRE_WEIGHT = 0.1
def pearsonR(s1, s2):  # 피어슨 상관관계를 만드는 함수
    s1_c = s1 - s1.mean()
    s2_c = s2 - s2.mean()
    return np.exp(logsumexp(np.sum(s1_c * s2_c))) / np.exp(logsumexp(np.sqrt(np.sum(s1_c ** 2)))) * np.exp(logsumexp(np.sum(s2_c ** 2)))
    # 분자가 클수록 상관관계가 높다.
        # 유저가 넣은 영화 / 피벗테이블 /반환값 /장르별 가중치를 할지 선택
def recommend(input_movie, matrix, n, similar_genre=True):
    input_genres = meta[meta['original_title'] == input_movie]['genres'].iloc(0)[0]
    # 값을 넣은 movie와 meta가 같을 때  origin_title의 장르를 가져온다.
    result = []
    for title in matrix.columns:
        if title == input_movie: # 타이틀과 input_movie가 같으면 넘긴다.
            continue

        # rating comparison
        # 매트릭스의 컬럼이름으로 루프를 돈다. title은 그 제목이고
        # 여기서 매트릭스의 타이틀이름과 inputmovice 를 넣고 피어슨 상관관계를 본다.
        cor = pearsonR(matrix[input_movie], matrix[title]) #피어슨 선형관계
        #여기서 cor 값을 구하고 

        # genre comparison (장르별 가중치를 두는 작업)
        if similar_genre and len(input_genres) > 0: # 장르별 가중치가 있고 장르가 있을 경우
            #루프 돌고있는 matirx의 컬럼명 값이 영화 제목을 만나면 장르값을 저장한다.
            temp_genres = meta[meta['original_title'] == title]['genres'].iloc(0)[0]
            # np.sum으로 리스트에 있는 값들을 합친다?
            # 찾는 값이 있는지에 따라 true false를 반환한다. 왼쪽에 오른쪽 값이 있는지 확인한다.
            # 그에따라 true 개수를 세서 같은게 몇개있는지 분석한다.
            same_count = np.sum(np.isin(input_genres, temp_genres))

            #선형관계에서 나온 계수에 장르별 가중치를 더해준다.
            cor += (GENRE_WEIGHT * same_count)
        
        if np.isnan(cor): # 값이 없으면 넘기고
            continue
        else: #값이 있으면 result라는 리스트에 값을 넣는다.
            result.append((title, '{:.2f}'.format(cor), temp_genres))
    # 정렬해준다.
    result.sort(key=lambda r: r[1], reverse=True)

    return result[:n]

recommend_result = recommend('The Dark Knight', matrix, 10, similar_genre=True)

pd.DataFrame(recommend_result, columns = ['Title', 'Correlation', 'Genre'])

